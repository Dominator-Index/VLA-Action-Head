"""
calculate_hyperbolicity_dataset_final.py

åœ¨è®­ç»ƒæ•°æ®é›†ä¸­è®¡ç®—actions_hidden_statesçš„hyperbolicity (Chunkçº§åˆ«)
"""

import os
import sys
import torch
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
from dataclasses import dataclass
from typing import Dict, Optional, List, Tuple
import json
from tqdm import tqdm
import glob

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ["CUDA_VISIBLE_DEVICES"] = "1"
sys.path.append("/home/ouyangzl/openvla-oft/")
sys.path.insert(0, "/home/ouyangzl/openvla-oft/prismatic/extern/hf")
sys.path.append("/home/ouyangzl/openvla-oft/Hyperbolicity/manifold")  # ä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼ŒåŸºäºå½“å‰å·¥ä½œç›®å½•ç»“æ„
from poincare import PoincareBall

# å¯¼å…¥å¿…è¦çš„æ¨¡å—
from transformers import AutoConfig, AutoImageProcessor, AutoModelForVision2Seq, AutoProcessor
from torch.utils.data import DataLoader
from scipy.spatial import distance_matrix

from prismatic.extern.hf.configuration_prismatic import OpenVLAConfig
from prismatic.extern.hf.modeling_prismatic import OpenVLAForActionPrediction
from prismatic.extern.hf.processing_prismatic import PrismaticImageProcessor, PrismaticProcessor
from prismatic.models.action_heads import (
    DiffusionActionHead, 
    L1RegressionActionHead, 
    VAEActionHead, 
    FlowMatchingActionHead, 
    OTFlowMatchingActionHead, 
    COTFlowMatchingActionHead,
    EndToEndDiffusionActionHead  
)
from prismatic.models.backbones.llm.prompting import PurePromptBuilder
from prismatic.models.projectors import (
    NoisyActionProjector,
    ProprioProjector,
)
from prismatic.training.train_utils import (
    get_current_action_mask,
    get_next_actions_mask,
)
from prismatic.util.data_utils import PaddedCollatorForActionPrediction
from prismatic.vla.action_tokenizer import ActionTokenizer
from prismatic.vla.constants import (
    ACTION_DIM,
    NUM_ACTIONS_CHUNK,
    PROPRIO_DIM,
)
from prismatic.vla.datasets import RLDSBatchTransform, RLDSDataset

# Hyperbolicityè®¡ç®—ç›¸å…³
from sklearn.decomposition import PCA
sys.path.append("/home/ouyangzl/openvla-oft/Hyperbolicity/manifold")  

@dataclass
class HyperbolicityConfig:
    """Hyperbolicityè®¡ç®—é…ç½®"""
    # æ¨¡å‹å’Œæ•°æ®è·¯å¾„
    vla_path: str = "/home/ouyangzl/openvla-oft/Finetune_logs_checkpoints/openvla-7b+libero_spatial_no_noops+b8+lr-0.0005+lora-r32+dropout-0.0--image_aug--VAE--80000_chkpt"
    data_root_dir: Path = Path("/mnt/nas_ailab_434/434_dataset/modified_libero_rlds")
    dataset_name: str = "libero_spatial_no_noops"
    
    # æ¨¡å‹é…ç½®
    use_l1_regression: bool = False
    use_vae: bool = True
    use_diffusion: bool = False
    use_flow_matching: bool = False
    use_ot_flow_matching: bool = False
    use_end_to_end_diffusion: bool = False
    use_proprio: bool = True
    use_film: bool = False
    num_images_in_input: int = 1
    
    # é‡‡æ ·é…ç½®
    batch_size: int = 8
    max_batches: int = 100  # é™åˆ¶å¤„ç†çš„batchæ•°é‡ï¼Œé¿å…å†…å­˜æº¢å‡º
    
    # Hyperbolicityè®¡ç®—é…ç½®ï¼ˆåªç”¨chunkçº§åˆ«ï¼‰
    n_tries: int = 10  # æ‰¹é‡è®¡ç®—hyperbolicityçš„å°è¯•æ¬¡æ•°
    batch_size_hyp: int = 2000  # æ¯æ¬¡hyperbolicityè®¡ç®—çš„batchå¤§å°
    
    # è¾“å‡ºé…ç½®
    output_dir: str = "./hyperbolicity_results_chunk_level_L1finetuned-libero-spatial"
    save_embeddings: bool = True
    
    def __post_init__(self):
        """åˆå§‹åŒ–åå¤„ç†ï¼Œè‡ªåŠ¨ç”Ÿæˆoutput_dir"""
        self.output_dir = self._generate_output_dir()
    
    def _generate_output_dir(self) -> str:
        """æ ¹æ®vla_pathå’Œæ¨¡å‹é…ç½®ç”Ÿæˆç»“æ„åŒ–è¾“å‡ºè·¯å¾„"""
        # è§£ævla_pathè·å–åŸºç¡€å‚æ•°
        vla_filename = os.path.basename(self.vla_path)
        main_params = vla_filename.split('--')[0].split('+')
        
        # æå–å…³é”®è®­ç»ƒå‚æ•°
        model_name = main_params[0]
        dataset = main_params[1]
        batch_size = main_params[2]
        lr = main_params[3]
        lora = main_params[4]
        dropout = main_params[5]
        
        # ç¡®å®šaction headç±»å‹
        action_head_type = self._get_action_head_type()
        
        # æå–è®­ç»ƒæ­¥æ•°
        step = self._extract_step_from_vla_path(vla_filename)
        
        # æ„å»ºè·¯å¾„ç»„ä»¶
        path_components = [
            model_name, dataset, batch_size, lr, lora, dropout,
            action_head_type,
            f"proprio-{self.use_proprio}",
            f"num_images-{self.num_images_in_input}",
            f"{step}_step"
        ]
        
        # ç»„åˆå®Œæ•´è·¯å¾„
        return os.path.join(
            "/home/ouyangzl/openvla-oft/Hyperbolicity/hyperbolicity_results_chunk_level",
            "+".join(path_components)
        )
    
    def _get_action_head_type(self) -> str:
        """æ ¹æ®æ¨¡å‹é…ç½®ç¡®å®šaction headç±»å‹"""
        if self.use_l1_regression: return "L1"
        if self.use_vae: return "VAE"
        if self.use_diffusion: return "Diffusion"
        if self.use_flow_matching: return "FlowMatching"
        if self.use_ot_flow_matching: return "OTFlowMatching"
        if self.use_end_to_end_diffusion: return "EndToEndDiffusion"
        return "Unknown"
    
    def _extract_step_from_vla_path(self, vla_filename: str) -> str:
        """ä»vla_pathæå–è®­ç»ƒæ­¥æ•°"""
        parts = vla_filename.split('--')
        if len(parts) >= 3 and parts[-1].endswith('_chkpt'):
            return parts[-1].replace('_chkpt', '')
        return "unknown_step"


def delta_hyp(dismat):
    """
    è®¡ç®—è·ç¦»çŸ©é˜µçš„delta hyperbolicityå€¼
    åŸºäºGromov Î´-hyperbolicityå®šä¹‰
    
    Args:
        dismat: è·ç¦»çŸ©é˜µ (n_points, n_points)
        
    Returns:
        delta: hyperbolicityå€¼
    """
    p = 0  # é€‰æ‹©åŸºå‡†ç‚¹
    row = dismat[p, :][np.newaxis, :]
    col = dismat[:, p][:, np.newaxis]
    XY_p = 0.5 * (row + col - dismat)

    maxmin = np.max(np.minimum(XY_p[:, :, None], XY_p[None, :, :]), axis=1)
    return np.max(maxmin - XY_p)


def batched_delta_hyp(X, n_tries=10, batch_size=1500):
    """
    æ‰¹é‡è®¡ç®—hyperbolicityä»¥æé«˜ç¨³å®šæ€§
    
    Args:
        X: åµŒå…¥å‘é‡çŸ©é˜µ (n_samples, n_dims)
        n_tries: å°è¯•æ¬¡æ•°
        batch_size: æ¯æ¬¡é‡‡æ ·çš„batchå¤§å°
        
    Returns:
        mean_delta_rel: ç›¸å¯¹deltaçš„å‡å€¼
        std_delta_rel: ç›¸å¯¹deltaçš„æ ‡å‡†å·®
    """
    vals = []
    n_samples = len(X)
    
    for i in tqdm(range(n_tries), desc="Computing batched hyperbolicity"):
        # éšæœºé‡‡æ ·
        if n_samples > batch_size:
            idx = np.random.choice(n_samples, batch_size, replace=False)
            X_batch = X[idx]
        else:
            X_batch = X
        
        # è®¡ç®—è·ç¦»çŸ©é˜µ
        distmat = distance_matrix(X_batch, X_batch)
        diam = np.max(distmat)
        
        # é¿å…é™¤é›¶
        if diam > 1e-8:
            delta_rel = 2 * delta_hyp(distmat) / diam
            vals.append(delta_rel)
    
    if vals:
        return np.mean(vals), np.std(vals)
    else:
        return 0.0, 0.0


def visualize_poincare_disk(embeddings: np.ndarray, labels: List[str], save_path: str):
    """
    ä½¿ç”¨Poincareçƒé¢çš„æŒ‡æ•°æ˜ å°„å°†embeddingsæŠ•å½±åˆ°Poincareç›˜å¹¶å¯è§†åŒ–
    
    Args:
        embeddings: åµŒå…¥å‘é‡ï¼Œshapeä¸º(n_samples, n_dims)
        labels: æ¯ä¸ªæ ·æœ¬çš„æ ‡ç­¾
        save_path: ä¿å­˜è·¯å¾„
    """
    print(f"Visualizing {embeddings.shape[0]} embeddings with {embeddings.shape[1]} dimensions using Poincare exponential map")
    
    # åˆå§‹åŒ–Poincareçƒé¢
    poincare_ball = PoincareBall()
    curvature = torch.tensor(1.0)  # è®¾ç½®æ›²ç‡å‚æ•°
    
    # å°†embeddingsè½¬æ¢ä¸ºtorch tensor
    embeddings_torch = torch.from_numpy(embeddings).float()
    
    # å¦‚æœç»´åº¦å¤§äº2ï¼Œç”¨PCAç›´æ¥é™ç»´åˆ°2ç»´ç”¨äºå¯è§†åŒ–
    if embeddings.shape[1] > 2:
        pca = PCA(n_components=2)
        embeddings_reduced = pca.fit_transform(embeddings)
        embeddings_torch = torch.from_numpy(embeddings_reduced).float()
        explained_var_ratio = pca.explained_variance_ratio_
        print(f"PCA explained variance ratio: {explained_var_ratio}")
        print(f"Total explained variance: {np.sum(explained_var_ratio):.4f}")
    elif embeddings.shape[1] == 1:
        # å¦‚æœåªæœ‰1ç»´ï¼Œè¡¥ä¸€ä¸ªé›¶ç»´åº¦
        embeddings_torch = torch.cat([embeddings_torch, torch.zeros_like(embeddings_torch)], dim=1)
    
    # å…¨å±€å½’ä¸€åŒ–ï¼šé™¤ä»¥æœ€å¤§normæ¥ä¿æŒç›¸å¯¹å…³ç³»
    max_norm = torch.norm(embeddings_torch, dim=1).max()
    print(f"Original max norm: {max_norm:.4f}")
    
    # ç¼©æ”¾æ‰€æœ‰å‘é‡ï¼Œä¿æŒç›¸å¯¹å¤§å°å…³ç³»
    scale_factor = 0.8  # æ§åˆ¶æ˜ å°„çš„èŒƒå›´ï¼Œé¿å…æ˜ å°„åˆ°è¾¹ç•Œ
    embeddings_scaled = embeddings_torch / max_norm * scale_factor
    
    print(f"After scaling - max norm: {torch.norm(embeddings_scaled, dim=1).max():.4f}")
    print(f"After scaling - min norm: {torch.norm(embeddings_scaled, dim=1).min():.4f}")
    print(f"After scaling - mean norm: {torch.norm(embeddings_scaled, dim=1).mean():.4f}")
    
    # ä½¿ç”¨Poincareçƒé¢çš„åŸç‚¹æŒ‡æ•°æ˜ å°„ï¼ˆexpmap0ï¼‰å°†åˆ‡å‘é‡æ˜ å°„åˆ°Poincareç›˜
    with torch.no_grad():
        poincare_points = poincare_ball.expmap0(embeddings_scaled, curvature)
    
    # è½¬æ¢å›numpyï¼Œç°åœ¨åº”è¯¥æ˜¯2ç»´çš„
    embeddings_2d = poincare_points.numpy()
    
    # ç¡®ä¿æ‰€æœ‰ç‚¹éƒ½åœ¨å•ä½åœ†å†…ï¼ˆPoincareçƒé¢çš„æ€§è´¨ï¼‰
    norms = np.linalg.norm(embeddings_2d, axis=1)
    max_norm_mapped = np.max(norms)
    min_norm_mapped = np.min(norms)
    mean_norm_mapped = np.mean(norms)
    
    print(f"After Poincare mapping - max norm: {max_norm_mapped:.4f}")
    print(f"After Poincare mapping - min norm: {min_norm_mapped:.4f}")
    print(f"After Poincare mapping - mean norm: {mean_norm_mapped:.4f}")
    
    # å¦‚æœæœ‰ç‚¹è¶…å‡ºè¾¹ç•Œï¼Œè¿›è¡Œå¾®è°ƒï¼ˆç†è®ºä¸Šä¸åº”è¯¥å‘ç”Ÿï¼‰
    if max_norm_mapped >= 1.0:
        embeddings_2d = embeddings_2d / max_norm_mapped * 0.95
        print("Warning: Some points were outside the Poincare disk, rescaled.")
    
    # åˆ›å»ºå›¾å½¢
    fig, ax = plt.subplots(1, 1, figsize=(12, 12))
    
    # ç»˜åˆ¶å•ä½åœ†ï¼ˆPoincareç›˜è¾¹ç•Œï¼‰
    circle = plt.Circle((0, 0), 1, fill=False, color='black', linewidth=3)
    ax.add_patch(circle)
    
    # ç»˜åˆ¶ä¸€äº›è¾…åŠ©çº¿ï¼ˆç½‘æ ¼ï¼‰
    for r in [0.25, 0.5, 0.75]:
        circle_grid = plt.Circle((0, 0), r, fill=False, color='gray', linewidth=1, alpha=0.3)
        ax.add_patch(circle_grid)
    
    # æ ¹æ®æ ‡ç­¾ç€è‰²
    unique_labels = list(set(labels))
    colors = plt.cm.Set3(np.linspace(0, 1, len(unique_labels)))
    
    for i, label in enumerate(unique_labels):
        mask = np.array(labels) == label
        ax.scatter(embeddings_2d[mask, 0], embeddings_2d[mask, 1], 
                  c=[colors[i]], label=f'Chunk {label}', alpha=0.8, s=60, edgecolors='black', linewidth=0.5)
    
    # æ·»åŠ åŸç‚¹æ ‡è®°
    ax.scatter(0, 0, c='red', s=100, marker='x', linewidth=3, label='Origin')
    
    ax.set_xlim(-1.1, 1.1)
    ax.set_ylim(-1.1, 1.1)
    ax.set_aspect('equal')
    ax.set_title('Action Chunk Hidden States in Poincare Disk\n(Exponential Map from Origin)', fontsize=14)
    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    ax.grid(True, alpha=0.3)
    
    # æ·»åŠ ä¸€äº›ç»Ÿè®¡ä¿¡æ¯
    ax.text(-1.05, -1.05, f'Total points: {len(embeddings_2d)}\nNorm range: [{min_norm_mapped:.3f}, {max_norm_mapped:.3f}]', 
           fontsize=10, bbox=dict(boxstyle="round,pad=0.3", facecolor="wheat", alpha=0.7))
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"Poincare disk visualization saved to {save_path}")
    
    # è®¡ç®—å¹¶æ‰“å°ä¸€äº›Poincareå‡ ä½•ç»Ÿè®¡
    with torch.no_grad():
        poincare_points_torch = torch.from_numpy(embeddings_2d).float()
        
        # è®¡ç®—ä»åŸç‚¹çš„Poincareè·ç¦»
        origin = torch.zeros_like(poincare_points_torch[:1])
        poincare_distances = []
        for point in poincare_points_torch:
            dist = poincare_ball.sqdist(origin[0:1], point.unsqueeze(0), curvature).sqrt()
            poincare_distances.append(dist.item())
        
        poincare_distances = np.array(poincare_distances)
        print(f"Poincare distance statistics:")
        print(f"  Mean distance from origin: {np.mean(poincare_distances):.4f}")
        print(f"  Std distance from origin: {np.std(poincare_distances):.4f}")
        print(f"  Max distance from origin: {np.max(poincare_distances):.4f}")
        print(f"  Min distance from origin: {np.min(poincare_distances):.4f}")


def load_model_and_components(cfg: HyperbolicityConfig):
    """åŠ è½½VLAæ¨¡å‹å’Œç›¸å…³ç»„ä»¶"""
    print("Loading VLA model and components...")
    
    # æ³¨å†Œæ¨¡å‹ç±»
    AutoConfig.register("openvla", OpenVLAConfig)
    AutoImageProcessor.register(OpenVLAConfig, PrismaticImageProcessor)
    AutoProcessor.register(OpenVLAConfig, PrismaticProcessor)
    AutoModelForVision2Seq.register(OpenVLAConfig, OpenVLAForActionPrediction)
    
    # åŠ è½½æ¨¡å‹
    processor = AutoProcessor.from_pretrained(cfg.vla_path, trust_remote_code=True)
    vla = AutoModelForVision2Seq.from_pretrained(
        cfg.vla_path,
        torch_dtype=torch.bfloat16,
        low_cpu_mem_usage=True,
        trust_remote_code=True,
    ).cuda()
    
    vla.vision_backbone.set_num_images_in_input(cfg.num_images_in_input)
    vla.eval()
    
    print(f"VLA model loaded. LLM dimension: {vla.llm_dim}")
    
    # åŠ è½½action head
    action_head = None
    if cfg.use_l1_regression:
        action_head = L1RegressionActionHead(
            input_dim=vla.llm_dim, hidden_dim=vla.llm_dim, action_dim=ACTION_DIM
        )
    elif cfg.use_vae:
        action_head = VAEActionHead(
            input_dim=vla.llm_dim, hidden_dim=vla.llm_dim, action_dim=ACTION_DIM, latent_dim=32
        )
    elif cfg.use_flow_matching:
        action_head = FlowMatchingActionHead(
            input_dim=vla.llm_dim, hidden_dim=vla.llm_dim, action_dim=ACTION_DIM, num_flow_steps=50
        )
    elif cfg.use_diffusion:
        action_head = DiffusionActionHead(
            input_dim=vla.llm_dim, hidden_dim=vla.llm_dim, action_dim=ACTION_DIM, num_diffusion_steps=50
        )
    elif cfg.use_end_to_end_diffusion:
        action_head = EndToEndDiffusionActionHead(
            input_dim=vla.llm_dim, hidden_dim=vla.llm_dim, action_dim=ACTION_DIM, num_diffusion_steps=50
        )
    
    if action_head is not None:
        # åŠ è½½checkpoint
        checkpoint_files = glob.glob(os.path.join(cfg.vla_path, "action_head--*_checkpoint.pt"))
        if checkpoint_files:
            print(f"Loading action head from {checkpoint_files[0]}")
            state_dict = torch.load(checkpoint_files[0], map_location='cpu', weights_only=True)
            # ç§»é™¤DDPå‰ç¼€
            new_state_dict = {}
            for k, v in state_dict.items():
                if k.startswith("module."):
                    new_state_dict[k[7:]] = v
                else:
                    new_state_dict[k] = v
            action_head.load_state_dict(new_state_dict)
        
        action_head = action_head.to(torch.bfloat16).cuda()
        action_head.eval()
        print("Action head loaded and moved to GPU")
    
    # åŠ è½½proprio projector
    proprio_projector = None
    if cfg.use_proprio:
        proprio_projector = ProprioProjector(llm_dim=vla.llm_dim, proprio_dim=PROPRIO_DIM)
        checkpoint_files = glob.glob(os.path.join(cfg.vla_path, "proprio_projector--*_checkpoint.pt"))
        if checkpoint_files:
            print(f"Loading proprio projector from {checkpoint_files[0]}")
            state_dict = torch.load(checkpoint_files[0], map_location='cpu', weights_only=True)
            new_state_dict = {}
            for k, v in state_dict.items():
                if k.startswith("module."):
                    new_state_dict[k[7:]] = v
                else:
                    new_state_dict[k] = v
            proprio_projector.load_state_dict(new_state_dict)
        
        proprio_projector = proprio_projector.to(torch.bfloat16).cuda()
        proprio_projector.eval()
        print("Proprio projector loaded and moved to GPU")
    
    return vla, action_head, proprio_projector, processor


def extract_chunk_level_embeddings(
    vla, action_head, proprio_projector, processor, dataloader, cfg: HyperbolicityConfig
) -> Tuple[np.ndarray, List[int], List[np.ndarray]]:
    """
    ä»æ•°æ®é›†ä¸­æå–chunkçº§åˆ«çš„actions_hidden_states
    
    Returns:
        all_chunk_embeddings: æ‰€æœ‰chunkçš„embeddingsåˆå¹¶ (n_total_samples, hidden_dim)
        chunk_labels: æ¯ä¸ªembeddingå¯¹åº”çš„chunkæ ‡ç­¾
        embeddings_per_chunk: æŒ‰chunkåˆ†ç¦»çš„embeddingsåˆ—è¡¨
    """
    print("Extracting chunk-level actions hidden states...")
    print(f"Expected dimensions:")
    print(f"  - NUM_ACTIONS_CHUNK: {NUM_ACTIONS_CHUNK}")
    print(f"  - ACTION_DIM: {ACTION_DIM}")
    print(f"  - Total action tokens per sample: {NUM_ACTIONS_CHUNK * ACTION_DIM}")
    
    # åˆå§‹åŒ–å­˜å‚¨ - åªå…³æ³¨chunkçº§åˆ«
    all_embeddings_per_chunk = [[] for _ in range(NUM_ACTIONS_CHUNK)]
    
    with torch.no_grad():
        for batch_idx, batch in enumerate(tqdm(dataloader, desc="Processing batches")):
            if batch_idx >= cfg.max_batches:
                break
                
            # å°†batchç§»åˆ°GPU
            batch = {k: v.cuda() if torch.is_tensor(v) else v for k, v in batch.items()}
            
            # VLAå‰å‘ä¼ æ’­
            with torch.autocast("cuda", dtype=torch.bfloat16):
                output = vla(
                    input_ids=batch["input_ids"],
                    attention_mask=batch["attention_mask"],
                    pixel_values=batch["pixel_values"].to(torch.bfloat16),
                    labels=batch["labels"],
                    output_hidden_states=True,
                    proprio=batch["proprio"] if cfg.use_proprio else None,
                    proprio_projector=proprio_projector if cfg.use_proprio else None,
                    use_film=cfg.use_film,
                )
            
            # è·å–action masks
            ground_truth_token_ids = batch["labels"][:, 1:]
            current_action_mask = get_current_action_mask(ground_truth_token_ids)
            next_actions_mask = get_next_actions_mask(ground_truth_token_ids)
            all_actions_mask = current_action_mask | next_actions_mask
            
            # è®¡ç®—patchæ•°é‡
            NUM_PATCHES = vla.vision_backbone.get_num_patches() * vla.vision_backbone.get_num_images_in_input()
            if cfg.use_proprio:
                NUM_PATCHES += 1
            
            # æå–actions hidden states
            last_hidden_states = output.hidden_states[-1]  # (B, seq_len, D)
            text_hidden_states = last_hidden_states[:, NUM_PATCHES:-1]
            
            batch_size = batch["input_ids"].shape[0]
            hidden_dim = last_hidden_states.shape[-1]
            
            # é‡è¦ï¼šç¡®ä¿ç»´åº¦æ­£ç¡®
            actions_hidden_states = (
                text_hidden_states[all_actions_mask]
                .reshape(batch_size, NUM_ACTIONS_CHUNK * ACTION_DIM, hidden_dim)
                .to(torch.float32)  # å…ˆè½¬æ¢ä¸ºfloat32
                .cpu().numpy()      # å†è½¬æ¢ä¸ºnumpy
            )
            
            print(f"Batch {batch_idx}: actions_hidden_states shape: {actions_hidden_states.shape}")
            
            # æŒ‰chunkçº§åˆ«å¤„ç†embeddings
            for batch_sample in range(batch_size):
                sample_embeddings = actions_hidden_states[batch_sample]  # (NUM_ACTIONS_CHUNK * ACTION_DIM, hidden_dim)
                
                # é‡å¡‘ä¸º (NUM_ACTIONS_CHUNK, ACTION_DIM, hidden_dim)
                chunk_embeddings = sample_embeddings.reshape(NUM_ACTIONS_CHUNK, ACTION_DIM, hidden_dim)
                
                # æ¯ä¸ªchunkå¹³å‡æ± åŒ–å¾—åˆ°chunkçº§åˆ«çš„embedding
                for chunk_idx in range(NUM_ACTIONS_CHUNK):
                    # å¯¹ACTION_DIMç»´åº¦è¿›è¡Œå¹³å‡æ± åŒ–: (ACTION_DIM, hidden_dim) -> (hidden_dim,)
                    chunk_embedding = np.mean(chunk_embeddings[chunk_idx], axis=0)  # axis=0æ˜¯å¯¹ACTION_DIMç»´åº¦å¹³å‡
                    all_embeddings_per_chunk[chunk_idx].append(chunk_embedding)
    
    # è½¬æ¢ä¸ºnumpyæ•°ç»„å¹¶åˆ›å»ºæ ‡ç­¾
    embeddings_per_chunk = []
    chunk_labels = []
    
    for chunk_idx in range(NUM_ACTIONS_CHUNK):
        if all_embeddings_per_chunk[chunk_idx]:
            embeddings = np.stack(all_embeddings_per_chunk[chunk_idx])
            embeddings_per_chunk.append(embeddings)
            chunk_labels.extend([chunk_idx] * len(embeddings))
            print(f"Chunk {chunk_idx}: {embeddings.shape[0]} samples, {embeddings.shape[1]} dimensions")
    
    # åˆå¹¶æ‰€æœ‰chunkçš„embeddings
    if embeddings_per_chunk:
        all_chunk_embeddings = np.vstack(embeddings_per_chunk)
        print(f"Total chunk embeddings shape: {all_chunk_embeddings.shape}")
        print(f"  - Total samples: {all_chunk_embeddings.shape[0]}")
        print(f"  - Hidden dimension: {all_chunk_embeddings.shape[1]}")
    else:
        all_chunk_embeddings = np.array([])
        
    return all_chunk_embeddings, chunk_labels, embeddings_per_chunk


def main():
    cfg = HyperbolicityConfig()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(cfg.output_dir, exist_ok=True)
    print(f"Output directory: {cfg.output_dir}")
    
    # åŠ è½½æ¨¡å‹å’Œç»„ä»¶
    vla, action_head, proprio_projector, processor = load_model_and_components(cfg)
    
    # åˆ›å»ºæ•°æ®é›†å’Œdataloader
    print("Loading dataset...")
    action_tokenizer = ActionTokenizer(processor.tokenizer)
    
    batch_transform = RLDSBatchTransform(
        action_tokenizer,
        processor.tokenizer,
        image_transform=processor.image_processor.apply_transform,
        prompt_builder_fn=PurePromptBuilder,
        use_wrist_image=(cfg.num_images_in_input > 1),
        use_proprio=cfg.use_proprio,
    )
    
    dataset = RLDSDataset(
        cfg.data_root_dir,
        cfg.dataset_name,
        batch_transform,
        resize_resolution=tuple(vla.config.image_sizes),
        shuffle_buffer_size=10000,
        image_aug=False,  # ä¸ä½¿ç”¨æ•°æ®å¢å¼ºä»¥ä¿æŒä¸€è‡´æ€§
        train=True,
    )
    
    collator = PaddedCollatorForActionPrediction(
        processor.tokenizer.model_max_length, 
        processor.tokenizer.pad_token_id, 
        padding_side="right"
    )
    
    dataloader = DataLoader(
        dataset,
        batch_size=cfg.batch_size,
        sampler=None,
        collate_fn=collator,
        num_workers=0,
    )
    
    print(f"Dataset loaded. Processing {cfg.max_batches} batches with batch size {cfg.batch_size}")
    
    # æå–chunkçº§åˆ«çš„actions hidden states
    all_chunk_embeddings, chunk_labels, embeddings_per_chunk = extract_chunk_level_embeddings(
        vla, action_head, proprio_projector, processor, dataloader, cfg
    )
    
    if len(all_chunk_embeddings) == 0:
        print("ERROR: No embeddings extracted!")
        return
    
    # è®¡ç®—hyperbolicity
    results = {}
    
    print("\n" + "="*80)
    print("CALCULATING HYPERBOLICITY (CHUNK LEVEL)")
    print("="*80)
    
    # 1. æ•´ä½“chunk hyperbolicity
    print(f"Computing overall chunk-level hyperbolicity for {all_chunk_embeddings.shape[0]} samples...")
    mean_delta, std_delta = batched_delta_hyp(
        all_chunk_embeddings, 
        n_tries=cfg.n_tries, 
        batch_size=cfg.batch_size_hyp
    )
    
    results["chunk_level_overall"] = {
        "hyperbolicity_mean": float(mean_delta),
        "hyperbolicity_std": float(std_delta),
        "n_samples": all_chunk_embeddings.shape[0],
        "n_dims": all_chunk_embeddings.shape[1],
        "calculation_method": "chunk_level_pooling",
        "pooling_strategy": "mean_over_action_dimensions"
    }
    
    print(f"âœ… Overall chunk-level hyperbolicity: {mean_delta:.6f} Â± {std_delta:.6f}")
    
    # ä¿å­˜ç»“æœ
    results_file = os.path.join(cfg.output_dir, "hyperbolicity_results_chunk_level.json")
    with open(results_file, 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"\nâœ… Results saved to {results_file}")
    
    # å¯è§†åŒ–åˆ°Poincareç›˜
    print("\nCreating Poincare disk visualization...")
    visualize_poincare_disk(
        all_chunk_embeddings,
        chunk_labels,
        os.path.join(cfg.output_dir, "poincare_visualization_chunk_level.png")
    )
    
    # ä¿å­˜embeddings
    if cfg.save_embeddings:
        embeddings_file = os.path.join(cfg.output_dir, "chunk_level_embeddings.npz")
        np.savez(
            embeddings_file, 
            all_chunk_embeddings=all_chunk_embeddings,
            chunk_labels=np.array(chunk_labels),
            **{f"chunk_{i}_embeddings": emb for i, emb in enumerate(embeddings_per_chunk)}
        )
        print(f"âœ… Embeddings saved to {embeddings_file}")
    
    # åˆ›å»ºæ¯ä¸ªchunkçš„hyperbolicityå›¾è¡¨
    print("\nCreating chunk-wise hyperbolicity visualization...")
    
    chunk_indices = []
    chunk_means = []
    chunk_stds = []
    
    for chunk_idx in range(NUM_ACTIONS_CHUNK):
        key = f"chunk_{chunk_idx}"
        if key in results:
            chunk_indices.append(chunk_idx)
            chunk_means.append(results[key]["hyperbolicity_mean"])
            chunk_stds.append(results[key]["hyperbolicity_std"])
    
    if chunk_indices:
        fig, ax = plt.subplots(1, 1, figsize=(12, 8))
        
        bars = ax.bar(chunk_indices, chunk_means, yerr=chunk_stds, 
                     capsize=5, alpha=0.7, color='skyblue', 
                     edgecolor='black', linewidth=1)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, (bar, mean, std) in enumerate(zip(bars, chunk_means, chunk_stds)):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height + std + 0.001,
                   f'{mean:.4f}Â±{std:.4f}', 
                   ha='center', va='bottom', fontsize=10)
        
        ax.set_xlabel('Chunk Index', fontsize=12)
        ax.set_ylabel('Hyperbolicity (Î´)', fontsize=12)
        ax.set_title('Hyperbolicity per Action Chunk\n(Mean Pooling over Action Dimensions)', fontsize=14)
        ax.grid(True, alpha=0.3)
        ax.set_xticks(chunk_indices)
        
        # æ·»åŠ æ•´ä½“å¹³å‡çº¿
        overall_mean = results["chunk_level_overall"]["hyperbolicity_mean"]
        ax.axhline(y=overall_mean, color='red', linestyle='--', linewidth=2, 
                  label=f'Overall Mean: {overall_mean:.4f}')
        ax.legend()
        
        plt.tight_layout()
        plt.savefig(os.path.join(cfg.output_dir, "chunk_hyperbolicity_comparison.png"), 
                   dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… Chunk comparison visualization saved")
    
    # æœ€ç»ˆæ€»ç»“
    print("\n" + "="*80)
    print("HYPERBOLICITY ANALYSIS COMPLETED")
    print("="*80)
    print(f"ğŸ“Š Analysis Summary:")
    print(f"   â€¢ Processing method: Chunk-level (mean pooling over action dimensions)")
    print(f"   â€¢ Input dimensions: ({NUM_ACTIONS_CHUNK}, {ACTION_DIM}, hidden_dim) -> ({NUM_ACTIONS_CHUNK}, hidden_dim)")
    print(f"   â€¢ Total samples analyzed: {all_chunk_embeddings.shape[0]}")
    print(f"   â€¢ Embedding dimension: {all_chunk_embeddings.shape[1]}")
    
    if "chunk_level_overall" in results:
        chunk_result = results["chunk_level_overall"]
        print(f"   â€¢ Overall chunk-level hyperbolicity: {chunk_result['hyperbolicity_mean']:.6f} Â± {chunk_result['hyperbolicity_std']:.6f}")
    
    print(f"ğŸ“ Results saved in: {cfg.output_dir}")
    print("="*80)


if __name__ == "__main__":
    main()
    
 # # 2. æ¯ä¸ªchunkå•ç‹¬çš„hyperbolicity
    # print(f"\nComputing hyperbolicity for each individual chunk...")
    # for chunk_idx, embeddings in enumerate(embeddings_per_chunk):
    #     if len(embeddings) >= 10:  # éœ€è¦è¶³å¤Ÿçš„æ ·æœ¬
    #         mean_delta, std_delta = batched_delta_hyp(
    #             embeddings, 
    #             n_tries=max(5, cfg.n_tries // 2), 
    #             batch_size=min(cfg.batch_size_hyp, len(embeddings))
    #         )
            
    #         results[f"chunk_{chunk_idx}"] = {
    #             "hyperbolicity_mean": float(mean_delta),
    #             "hyperbolicity_std": float(std_delta),
    #             "n_samples": embeddings.shape[0],
    #             "n_dims": embeddings.shape[1]
    #         }
            
    #         print(f"  Chunk {chunk_idx}: {mean_delta:.6f} Â± {std_delta:.6f} (n={embeddings.shape[0]})")
    #     else:
    #         print(f"  Chunk {chunk_idx}: Not enough samples ({len(embeddings)} < 10)")